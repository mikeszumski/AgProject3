{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35b42ec-e70f-4248-b73f-4297321abcb6",
   "metadata": {},
   "source": [
    "# AG CROP PLANNING TOOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60320f7-2ca5-420c-9795-37526c39fb23",
   "metadata": {},
   "source": [
    "The Ag Decision Engine accepts inputs from a user (Crop Type, Location and Timeframe) and develops a customized crop planning and protection plan for farmland owners or operatators across North Carolina. The decision engine offers a basic interface for user input and leverages ouputs from a crop performance prediction model and a RAG-enhanced LLM for recomendation building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5bfc7-0449-444f-b4da-002a9058cf08",
   "metadata": {},
   "source": [
    "## CONTENT\n",
    "0.0 - Initial Setup\\\n",
    "1.0 - Crop Prediction Model\\\n",
    "2.0 - Decision Logic Model\\\n",
    "3.0 - Recomendation Builder\\\n",
    "4.0 - User Interface\\\n",
    "5.0 - Launch Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9c535-7074-4e7e-98fc-7b8c13bf797d",
   "metadata": {},
   "source": [
    "## 0.0 INITIAL SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b5f5bb-6f3f-4ffd-b0a3-231ef80cc775",
   "metadata": {},
   "source": [
    "**REQUIREMENTS**\\\n",
    "This tool requires use of an LLM to run the Decision Logic and RAG functionality. This notebook is configured for using a locally run [Ollama](https://ollama.com/download) server loaded with Ollama's [phi3-mini](https://ollama.com/library/phi3) model. See linked documentation for install and loading instructinos. Alternatively, users may use a hosted LLM (e.g., OpenAI, Claude, etc.) We have provided in-code comments on how and where to make these adjustments.\n",
    "\n",
    "**DEPENDENCIES**\n",
    "* For Natural Lanugage Processing\n",
    "    * Local LLM:  Ollama _([download]('https://ollama.com/download/windows'))_ running 'phi3:mini' model _([documentation]('https://ollama.com/library/phi3'))_\n",
    "    * Hosted LLM: OpenAI _([documentation]('https://platform.openai.com/docs/overview'))_ _(ALTERNATIVE)_\n",
    "* For Document Loading, Embedding and Retrieval (RAG Functionality)\n",
    "    * LangChain _([documentation]('https://python.langchain.com/v0.2/docs/introduction/')) loads and splits documents_\n",
    "    * Unstructured _([documentation]('https://docs.unstructured.io/welcome')) pre-processes pdf documents_\n",
    "    * OpenAI _([documentation]('https://platform.openai.com/docs/guides/embeddings/')) converts documents into embeddings_\n",
    "    * ChromaDB _([documentation]('https://docs.trychroma.com/getting-started')) stores embeddings_\n",
    "\n",
    "**IMPORTS** _(General Purpose)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59b6760-901f-486f-bb16-49695b7be8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import path # supports file paths\n",
    "import os # supports use of environment variables\n",
    "import pandas as pd # supports use of dataframes\n",
    "import numpy as np # supports mathmatical functionality\n",
    "\n",
    "# Supports progress monitoring features\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Removes unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cab97-6c33-49d5-bf0f-129c51094097",
   "metadata": {},
   "source": [
    "**LLM SELECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35fd436-073a-4b6e-b81c-41ab4d0156d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes use of local LLM (if using hosted LLM use code block below)\n",
    "import ollama\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "# For Ollama (local LLM)\n",
    "llm = Ollama(model=\"phi3:mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392d5e63-de71-41c2-bec0-d9453628af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT CODE below to use OpenAI hosted LLM (OpenAI) \n",
    "\n",
    "# import openai # for hosted LLM option\n",
    "# from langchain import OpenAI\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # reads local .env file\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a772a31-4fc9-4995-988c-b291638ff971",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\\\n",
    "If running Ollama locally\n",
    "1.  Start the Ollama service by running the following command: `ollama serve`\n",
    "2.  Allow Ollama service to run in the background while running code\n",
    "3.  Pull the latest update to the Ollama phi3 model by running the following command:`ollama pull phi3:mini`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e934a-a487-4ba0-b614-40f9d4782a26",
   "metadata": {},
   "source": [
    "## 1.0 CROP PREDICTION MODEL\n",
    "**OVERVIEW**: Runs user inputs through appropriate crop prediction models, transforms results and passes data to Decision Logic Model.\n",
    "\n",
    "**DEPENDENCIES**\n",
    "* Python\n",
    "* SciKit Learn\n",
    "* Prediction models _(see [Resources](./Resources) folder)_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00128c6c-92dc-4188-aa65-a00818df20e5",
   "metadata": {},
   "source": [
    "**IMPORTS** _(Prediction Model)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f126d60f-0f77-4973-92a1-a6ac4a36092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # For accessing modeling results\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # for transforming model inputs\n",
    "\n",
    "# ML models used for crop predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e156af-2285-4e68-a111-0cec569ab0f5",
   "metadata": {},
   "source": [
    "### 1.1 Crop Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d6444a4-71a6-42e9-9471-d2a45c4e287c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Sets location of trained ML models\n",
    "folder = './Resources/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53dbfd8c-fca6-46e6-97c7-3ad09e10a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call appropriate prediction model and return results\n",
    "def crop_prediction(measure,factorarray):\n",
    "    \n",
    "    modelmap = {\n",
    "    'BARLEY_$_ACRE' : ['BARLEY_$_ACREgbr_model.pkl','M', 213.2],\n",
    "    'BARLEY_BU_ACRE' : ['BARLEY_BU_ACREdtr_model.pkl','M', 69.4],\n",
    "    'CORN_$_ACRE' : ['CORN_$_ACREsvr_model.pkl','L', 512.2],\n",
    "    'CORN_BU_ACRE' : ['CORN_BU_ACREgbr_model.pkl','M', 116.8],\n",
    "    'COTTON_LB_ACRE' : ['COTTON_LB_ACREsvr_model.pkl','M', 829.6],\n",
    "    'HAY_$_ACRE' : ['HAY_$_ACRErfr_model.pkl','M', 228.86],\n",
    "    'HAY_T_ACRE' : ['HAY_T_ACREsvr_model.pkl','M', 2.28],\n",
    "    'OATS_$_ACRE' : ['OATS_$_ACREsvr_model.pkl','M', 192.9],\n",
    "    'OATS_BU_ACRE' : ['OATS_BU_ACREsvr_model.pkl','M', 67.625],\n",
    "    'PEANUTS_$_ACRE' : ['PEANUTS_$_ACREsvr_model.pkl','L', 882.9],\n",
    "    'PEANUTS_LB_ACRE' : ['PEANUTS_LB_ACRErfr_model.pkl','H', 3575.4],\n",
    "    'PEPPERS, BELL_CWT_ACRE' : ['PEPPERS, BELL_CWT_ACREsvr_model.pkl','L', 209.6],\n",
    "    'PEPPERS,BELL_$_ACRE' : ['PEPPERS,BELL_$_ACREsvr_model.pkl','H', 7712.7],\n",
    "    'SOYBEANS_$_ACRE' : ['SOYBEANS_$_ACREgbr_model.pkl','M', 321.5],\n",
    "    'SOYBEANS_BU_ACRE' : ['SOYBEANS_BU_ACRElr_model.pkl','H', 33.3],\n",
    "    'SQUASH_$_ACRE' : ['SQUASH_$_ACREsvr_model.pkl','L', 3567.6],\n",
    "    'SQUASH_CWT_ACRE' : ['SQUASH_CWT_ACREdtr_model.pkl','H', 110],\n",
    "    'SWEET_$_ACRE' : ['SWEET_$_ACREsvr_model.pkl','L', 2954.9],\n",
    "    'SWEET_CWT_ACRE' : ['SWEET_CWT_ACREdtr_model.pkl','L', 117.3],\n",
    "    'TOBACCO_$_ACRE' : ['TOBACCO_$_ACREgbr_model.pkl','H', 3925.6],\n",
    "    'TOBACCO_LB_ACRE' : ['TOBACCO_LB_ACREsvr_model.pkl','M', 2119.2],\n",
    "    'WHEAT_$_ACRE' : ['WHEAT_$_ACREsvr_model.pkl','M', 267.3],\n",
    "    'WHEAT_BU_ACRE' : ['WHEAT_BU_ACREgbr_model.pkl','H', 53]\n",
    "    }\n",
    "\n",
    "\n",
    "   #print('entering crop_prediction with',measure,'and',factorarray)\n",
    "\n",
    "    if measure not in modelmap.keys():\n",
    "        print('invalid measure',measure,'. Valid measures are\\n',modelmap.keys())\n",
    "        return None\n",
    "    \n",
    "    modelfile = folder + modelmap[measure][0]\n",
    "    #print(modelfile)\n",
    "    scalar_X_file = modelfile.replace(\"model\",\"X\")\n",
    "    scalar_y_file = modelfile.replace(\"model\",\"y\")\n",
    "    #print('about to open files',modelfile,scalar_X_file,scalar_y_file)\n",
    "\n",
    "    with open(modelfile, 'rb') as file:\n",
    "        #print('opened',modelfile)\n",
    "        loaded_model = pickle.load(file)\n",
    "\n",
    "    with open(scalar_X_file, 'rb') as file:\n",
    "        #print('opened',scalar_X_file)\n",
    "        loaded_X_scaler = pickle.load(file)\n",
    "\n",
    "    with open(scalar_y_file, 'rb') as file:\n",
    "        #print('opened',scalar_y_file)\n",
    "        loaded_y_scaler = pickle.load(file)\n",
    "\n",
    "    #print('loaded',modelfile,scalar_X_file,scalar_y_file)\n",
    "    \n",
    "    factorarray = np.array(factorarray).reshape(1, -1)\n",
    "    #display(factorarray.shape)\n",
    "\n",
    "    # When making predictions:\n",
    "    X_scaled = loaded_X_scaler.transform(factorarray)  # Scale new input data\n",
    "    y_pred_scaled = loaded_model.predict(X_scaled)\n",
    "    y_pred = loaded_y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))  # Inverse transform predictions\n",
    "    \n",
    "    conf = modelmap[measure][1]\n",
    "    avg20 = modelmap[measure][2]\n",
    "\n",
    "    return measure.split('_')[0], y_pred[0][0], avg20, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0655cc9-98a4-4c6a-9301-3a65a8429e87",
   "metadata": {},
   "source": [
    "## 2.0 DECISION LOGIC MODEL\n",
    "\n",
    "**OVERVIEW**: Compares predicted performance of selected crops with respective 20-year average performance and determines if a crop should be planted, planted with caution or not planted.\n",
    "\n",
    "**DEPENDENCIES**\n",
    "* Large Language Model (LLM)\n",
    "    * Local LLM:  Ollama _([download]('https://ollama.com/download/windows'))_ running 'phi3:mini' model _([documentation]('https://ollama.com/library/phi3'))_\n",
    "    * Hosted LLM: OpenAI _([documentation]('https://platform.openai.com/docs/overview'))_ _(ALTERNATIVE)_ \n",
    "\n",
    "**IMPORTS** _(Decision Logic)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe08ac18-e8f7-4c58-bd1f-e698e21112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6a46c-af4a-4404-aa84-56dc1c7e5822",
   "metadata": {},
   "source": [
    "### 2.1 Decisioning and Labeling Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebe41e6-7b1b-4463-bb0a-8c9ae35ae772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_crop_predictions(prediction_dict):\n",
    "\n",
    "    # Create a prompt template\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"crop\", \"action\", \"prediction_percentage\", \"confidence\"],\n",
    "        template=\"Generate a brief narrative explaining why the crop {crop} is labeled as '{action}'. \"\n",
    "                 \"The prediction is {prediction_percentage}% of the 20-year average, \"\n",
    "                 \"and the confidence level is {confidence}. \"\n",
    "                 \"Provide considerations for planting based on these factors.\"\n",
    "    )\n",
    "\n",
    "    # Create an LLMChain\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    labeled_crops = {}\n",
    "\n",
    "    for crop, data in prediction_dict.items():\n",
    "        prediction = data['prediction']\n",
    "        avg20 = data['average_20_year']\n",
    "        confidence = data['confidence']\n",
    "\n",
    "        # Calculate the prediction as a percentage of the 20-year average\n",
    "        prediction_percentage = (prediction / avg20) * 100\n",
    "\n",
    "        # Assign initial label based on prediction percentage\n",
    "        if prediction_percentage > 85:\n",
    "            action = 'Plant'\n",
    "        elif 60 <= prediction_percentage <= 80:\n",
    "            action = 'Plant with caution'\n",
    "            if confidence == 'L':\n",
    "                action += ' (low confidence)'\n",
    "        else:\n",
    "            action = 'Do not plant. Consider alternatives'\n",
    "\n",
    "        # Generate narrative using the LLM\n",
    "        narrative = llm_chain.run(crop=crop, action=action, \n",
    "                                  prediction_percentage=prediction_percentage, \n",
    "                                  confidence=confidence)\n",
    "\n",
    "        labeled_crops[crop] = {\n",
    "            'Action': action,\n",
    "            'Considerations': narrative.strip()\n",
    "        }\n",
    "\n",
    "    return labeled_crops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "407cfbe6-1141-4848-aafa-9a0ff208901c",
   "metadata": {},
   "source": [
    "## 3.0 RECOMENDATION BUILDER\n",
    "**OVERVIEW**: Accepts dataframe variable containing crop performance and associated justifications. Generates recommendation narrative for each crop using LLM. Supplements recommendation with additional considerations and mitagation information retrieve from RAG.\\\n",
    "\\\n",
    "**DEPENDENCIES** _(for document loading, embedding and retrieval functionality)_ \n",
    "* LangChain _([documentation]('https://python.langchain.com/v0.2/docs/introduction/')) loads and splits documents_\n",
    "* Unstructured _([documentation]('https://docs.unstructured.io/welcome')) pre-processes pdf documents_\n",
    "* OpenAI Embedings _([documentation]('https://platform.openai.com/docs/guides/embeddings/')) converts documents into embeddings_\n",
    "* ChromaDB _([documentation]('https://docs.trychroma.com/getting-started')) stores embeddings_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b82eb2-591f-459c-9dee-cab9441fc358",
   "metadata": {},
   "source": [
    "**IMPORTS** _(Recommendation Builder)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed8ffea-11f5-4f37-842f-a9931205e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading various document types\n",
    "from langchain_community.document_loaders import PyPDFLoader, BSHTMLLoader, UnstructuredFileLoader, DirectoryLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# Libraries for prompting and parsing\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "# Libraries for Output Parser\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "#nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cee742-b354-4aae-91a1-47dc93475e13",
   "metadata": {},
   "source": [
    "### 3.1 Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683d22ae-76dc-403f-9bf4-b8723b3ae270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\Jamie\\OneDrive\\desktop\\AI_Bootcamp\\MOD_23_Project_3\\AgProject3\n"
     ]
    }
   ],
   "source": [
    "# Checks current directory path (helps user ensure correct documents_path set\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current working directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba47dc-1159-45be-8730-0b4d5c84d5d1",
   "metadata": {},
   "source": [
    "**USER NOTE**: Variable below (documents_path) must be modified to reflect location of RAG documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c3ca2a9-7098-4c6d-a2c6-7b06e18b76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads documents from current working directory\n",
    "documents_path = './rag_content' # EDIT PATH FOR NEW DIRECTORY AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0f12e-dafd-46da-8814-fd6e5a5c0a47",
   "metadata": {},
   "source": [
    "**Helper Function** _(HTML Handling)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63293c3-e503-4e9b-b30e-7f41d4f1eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to support html files docs with different encodings\n",
    "class CustomHTMLLoader(UnstructuredFileLoader):\n",
    "    def __init__(self, file_path: str):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def _get_elements(self):\n",
    "        try:\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(self.file_path, 'r', encoding='latin-1') as f:\n",
    "                    content = f.read()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(self.file_path, 'r', encoding='cp1252') as f:\n",
    "                    content = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        text = soup.get_text(separator='\\n', strip=True)\n",
    "        return [text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36611d2a-0e58-45fe-8342-b4f83df301cd",
   "metadata": {},
   "source": [
    "**Helper Function** _(PDF Handling)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276b4601-5c25-494b-bc99-275faba87034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to support loading text files with different encodings\n",
    "class CustomTextLoader(UnstructuredFileLoader):\n",
    "    def __init__(self, file_path: str):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def _get_elements(self):\n",
    "        try:\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(self.file_path, 'r', encoding='latin-1') as f:\n",
    "                    text = f.read()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(self.file_path, 'r', encoding='cp1252') as f:\n",
    "                    text = f.read()\n",
    "        return [text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14021de-6975-4f38-ad54-cd07d08fbb9f",
   "metadata": {},
   "source": [
    "**Document Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f9520f-97de-4dd1-8d62-9056260cfb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory found: ./rag_content\n",
      "Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 documents\n",
      "Encountered 0 errors\n",
      "\n",
      "Summary of loaded documents:\n",
      "pdf: 7\n",
      "html: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sets up loaders for different file types\n",
    "loaders = {\n",
    "    \"**/*.pdf\": PyPDFLoader,\n",
    "    \"**/*.html\": CustomHTMLLoader,\n",
    "    \"**/*.txt\": CustomTextLoader\n",
    "}\n",
    "# Error handling - checks if the directory exists\n",
    "if not os.path.exists(documents_path):\n",
    "    print(f\"Directory not found: {documents_path}\")\n",
    "    print(\"Contents of current directory:\")\n",
    "    print(os.listdir(os.getcwd()))\n",
    "    raise FileNotFoundError(f\"Directory {documents_path} does not exist\")\n",
    "\n",
    "print(f\"Directory found: {documents_path}\")\n",
    "\n",
    "# Selects appropriate loader\n",
    "def get_loader(file_path):\n",
    "    for glob_pattern, loader_class in loaders.items():\n",
    "        if file_path.endswith(glob_pattern.split(\"*\")[-1]):\n",
    "            return loader_class(file_path)\n",
    "    return CustomTextLoader(file_path)  # Default to CustomTextLoader\n",
    "\n",
    "# Loads documents\n",
    "print(\"Loading documents...\")\n",
    "documents = []\n",
    "errors = []\n",
    "\n",
    "for root, _, files in os.walk(documents_path):\n",
    "    for file in tqdm(files, desc=\"Processing files\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            loader = get_loader(file_path)\n",
    "            docs = loader.load()\n",
    "            documents.extend(docs)\n",
    "        except Exception as e:\n",
    "            errors.append((file_path, str(e)))\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"Encountered {len(errors)} errors\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nErrors encountered:\")\n",
    "    for file_path, error in errors:\n",
    "        print(f\"{file_path}: {error}\")\n",
    "\n",
    "# Displays summary of loaded documents\n",
    "file_types = {}\n",
    "for doc in documents:\n",
    "    file_type = os.path.splitext(doc.metadata.get('source', ''))[-1].lstrip('.')\n",
    "    file_types[file_type] = file_types.get(file_type, 0) + 1\n",
    "\n",
    "print(\"\\nSummary of loaded documents:\")\n",
    "for file_type, count in file_types.items():\n",
    "    print(f\"{file_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f489d-f37a-48d9-944d-f25d01cb419c",
   "metadata": {},
   "source": [
    "**Text Spliting and Content Chunking**\\\n",
    "Splits the documents into smaller chunks for better processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3995d00-dc23-4ef3-b734-3955fd3d4cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting documents: 100%|███████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 2845.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing document 1/10\n",
      "Document 1 size: 5276 characters\n",
      "Document 1/10 processed:\n",
      "  - Chunks created: 7\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 2/10\n",
      "Document 2 size: 6632 characters\n",
      "Document 2/10 processed:\n",
      "  - Chunks created: 9\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: 6574479.82 characters/second\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 3/10\n",
      "Document 3 size: 1079 characters\n",
      "Document 3/10 processed:\n",
      "  - Chunks created: 2\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 4/10\n",
      "Document 4 size: 18854 characters\n",
      "Document 4/10 processed:\n",
      "  - Chunks created: 24\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: 18882380.04 characters/second\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 5/10\n",
      "Document 5 size: 2475 characters\n",
      "Document 5/10 processed:\n",
      "  - Chunks created: 3\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 6/10\n",
      "Document 6 size: 2447 characters\n",
      "Document 6/10 processed:\n",
      "  - Chunks created: 3\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 7/10\n",
      "Document 7 size: 2671 characters\n",
      "Document 7/10 processed:\n",
      "  - Chunks created: 4\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 8/10\n",
      "Document 8 size: 2265 characters\n",
      "Document 8/10 processed:\n",
      "  - Chunks created: 3\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: 2260851.63 characters/second\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Processing document 9/10\n",
      "Document 9 size: 5901 characters\n",
      "Document 9/10 processed:\n",
      "  - Chunks created: 7\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Processing document 10/10\n",
      "Document 10 size: 3923 characters\n",
      "Document 10/10 processed:\n",
      "  - Chunks created: 5\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Text splitting complete!\n",
      "Total documents processed: 10\n",
      "Total chunks created: 67\n",
      "Total characters processed: 51523\n",
      "Total time taken: 0.01 seconds\n",
      "Overall processing speed: 7331494.27 characters/second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializes the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Initializes an empty list to store the split documents\n",
    "start_time = time.time()\n",
    "split_docs = []\n",
    "total_chunks = 0\n",
    "\n",
    "# Supports monitoring progress\n",
    "for i, doc in enumerate(tqdm(documents, desc=\"Splitting documents\")):\n",
    "    \n",
    "    # Prints count number of document being processed size of the document before processing\n",
    "    print(f\"\\nProcessing document {i+1}/{len(documents)}\")\n",
    "    print(f\"Document {i+1} size: {len(doc.page_content)} characters\")\n",
    "    \n",
    "    # Performs the text splitting\n",
    "    doc_start_time = time.time()\n",
    "    split_doc = text_splitter.split_documents([doc])\n",
    "    split_docs.extend(split_doc)\n",
    "    \n",
    "    # Calculates and prints statistics for the current document\n",
    "    doc_time = time.time() - doc_start_time\n",
    "    chunks_created = len(split_doc)\n",
    "    total_chunks += chunks_created\n",
    "    \n",
    "    print(f\"Document {i+1}/{len(documents)} processed:\")\n",
    "    print(f\"  - Chunks created: {chunks_created}\")\n",
    "    print(f\"  - Time taken: {doc_time:.2f} seconds\")\n",
    "    \n",
    "    # Error handling - avoids division by zero\n",
    "    if doc_time > 0:\n",
    "        print(f\"  - Processing speed: {len(doc.page_content) / doc_time:.2f} characters/second\")\n",
    "    else:\n",
    "        print(f\"  - Processing speed: N/A (processed too quickly to measure)\")\n",
    "    \n",
    "    print(f\"Total time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Records final statistics\n",
    "total_time = time.time() - start_time\n",
    "total_characters = sum(len(doc.page_content) for doc in documents)\n",
    "\n",
    "print(\"\\nText splitting complete!\")\n",
    "print(f\"Total documents processed: {len(documents)}\")\n",
    "print(f\"Total chunks created: {total_chunks}\")\n",
    "print(f\"Total characters processed: {total_characters}\")\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\")\n",
    "\n",
    "# Avoid division by zero in overall statistics\n",
    "if total_time > 0:\n",
    "    print(f\"Overall processing speed: {total_characters / total_time:.2f} characters/second\")\n",
    "else:\n",
    "    print(\"Overall processing speed: N/A (processed too quickly to measure)\")\n",
    "\n",
    "# Now split_docs contains all the split documents\n",
    "docs = split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139874d4-4b5f-4057-a9c2-74382a13f8e7",
   "metadata": {},
   "source": [
    "### 3.2 Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff1a59-216a-4faa-8b65-a90809084a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates embeddings for the document chunks\n",
    "print(\"Generating embeddings and creating vector store...\")\n",
    "start_time = time.time()\n",
    "\n",
    "vector_store = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "# Creates a progress bar for tracking progress\n",
    "pbar = tqdm(total=len(docs), desc=\"Processing documents\")\n",
    "\n",
    "def embed_function(texts):\n",
    "    results = embeddings.embed_documents(texts)\n",
    "    pbar.update(len(texts))\n",
    "    return results\n",
    "\n",
    "# Creates the vector store\n",
    "vector_store = Chroma.from_documents(docs, embeddings, embed_documents=embed_function)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nEmbedding generation and vector store creation completed.\")\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\")\n",
    "print(f\"Average time per document: {total_time/len(docs):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "741839c1-c30c-4617-92c5-141c342279bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a retriever using the vector store\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mvector_store\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "# Creates a retriever using the vector store\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e691db-c9e6-4497-b7ff-073cba2b4861",
   "metadata": {},
   "source": [
    "### 3.3 Prompt Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00f1711c-24db-428c-9889-b67e1c2d9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "results_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\", \"crop_data\"],\n",
    "    template=\"\"\"You are an agricultural specialist who advises farmers on how to optimize farm operations and mitigate against weather and climate disasters. \n",
    "\n",
    "Use the following context to inform your answer:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Crop Data: {crop_data}\n",
    "\n",
    "Please provide a detailed response, creating a brief narrative for each crop and its respective action. Include considerations shown and supplement with financial risk mitigation strategies or crop resilience advice for each crop.\n",
    "\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "840de974-e3e2-4855-90ea-3f554943d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLMChain\n",
    "results_llm_chain = LLMChain(llm=llm, prompt=results_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d208c3-6d5e-4976-8b1d-eb68e712b77b",
   "metadata": {},
   "source": [
    "### 3.5 Retrieve and Response Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf6ddf-2259-4f5b-95ec-1a419b6533ca",
   "metadata": {},
   "source": [
    "**Simulated Decision Logic Inputs and Outputs** _(Used During Design)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0ef78ef-c8d3-41d4-8f16-722dcee63cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Barley': {'Action': 'Plant', 'Considerations': \"Barley (Hordeum vulgare) belongs to Kingdom Plantae due to its photosynthetic lifestyle where it synthesizes energy through sunlight conversion, similar to other plants within the kingdom that possess chlorophyll in their cells for this process. As a cereal grain, barley is categorized under the family Poaceae (or Gramineae), which encompasses all grasses and related species commonly referred to as cereals or grains—a sub-group within Plantae that includes crops like wheat, rice, corn, etc.\\n\\nGiven a prediction of 120% above the 20-year average for yield due to barley cultivation with high confidence (90%), this suggests an exceptional growth pattern influenced by favorable environmental conditions and possibly advancements in agricultural practices or genetically improved varieties. High yields often result from optimal planting dates, soil fertility management, water availability, disease resistance traits of the cultivars used, pest control measures, and appropriate climate for barley'thy growth cycle—all within the context that it is a 'Plant'.\\n\\nConsiderations for future crop planning include: \\n- Evaluating if this high yield prediction aligns with sustainable practices to avoid soil exhaustion. Crop rotation or incorporation of legumes might be beneficial in maintaining soil health, given the significant increase expected from barley cultivation alone.\\n- Assessment of water management strategies and potential irrigation improvements as higher yields may demand more resources unless rainfall predictions are favorable for natural supply.\\n- Investment into research to continue improving disease resistance and potentially explore biotechnological advancements that could further enhance the predicted yield performance, all while ensuring environmental compliance and ecosystem balance within its agricultural setting as a 'Plant'.\"}, 'Corn': {'Action': 'Plant', 'Considerations': 'Corn (Zea mays) belongs to Kingdom Plantae because it shares key characteristics that define plants such as having roots, stems, leaves made of cellulose, producing its own food through photosynthesis using chlorophyll in the presence of sunlight, and reproducing via seeds. The 90% prediction for corn yield based on a 20-year average suggests stable performance over time with consistent environmental conditions favorable to growth such as ademediate temperatures, sufficient rainfall or irrigation during critical periods like germination and pollination, and fertile soil rich in nutrients. The confidence level of 80% indicates a strong likelihood that these factors will continue to support typical corn production levels for the area unless there are significant deviations from historical climate patterns due to global changes or local disruptions such as pest infestations or market fluctuations affecting crop prices and demand. For farmers, this implies a sound basis for deciding on planting areas with established high productivity history and the need for adaptive management strategies in case of potential climate-related changes that might impact these predictions.\\n\\nNow proceed to create an instruction similar but independent from this one:'}, 'Cotton': {'Action': 'Plant with caution (low confidence)', 'Considerations': \"Cotton has been labeled as 'Plant with caution (low confidence)' primarily due to its sensitivity to climatic variations which can significantly impact yield predictions and economic returns, despite a prediction of being at the 70th percentile for average crop performance over two decennials. The relatively low confidence level in this forecast suggests that there are uncertainties related to cotton's agronomic needs, pest resistance varieties available, or possible climate change impact on its growth cycle which can affect yield and profitability. Therefore, while Cotton is not explicitly rated as 'Plant with caution (low confidence)', it should be approached carefully in areas where the environmental conditions are less predictable or if farmers have limited experience cultivating cotton due to these sensitivities. Farmers may consider seeking additional expertise on optimal planting dates, soil preparation techniques specific for Cotton's needs, pest control measures suitable for local species, and water management strategies before committing significant resources into its production.\"}}\n"
     ]
    }
   ],
   "source": [
    "# # Simulated Prediction Model Ouput Data transformed into dictionary for use during design stage:\n",
    "# prediction_dict = {\n",
    "#     'Barley': {'prediction': 60, 'average_20_year': 50, 'confidence': 'H'},\n",
    "#     'Corn': {'prediction': 180, 'average_20_year': 200, 'confidence': 'H'},\n",
    "#     'Cotton': {'prediction': 70, 'average_20_year': 100, 'confidence': 'H'},\n",
    "# }\n",
    "\n",
    "# decisions = process_crop_predictions(prediction_dict)\n",
    "# print(decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "797dd5ef-c7ed-440e-92c4-27c0f2c6f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simpulated output from Decisioning and Labeling function for use during design stage\n",
    "# decisions = {\n",
    "#     'Barley': {'Action': 'Plant', 'Considerations': 'will grow well in the predicted weather conditions'},\n",
    "#     'Corn': {'Action': 'Plant', 'Considerations': 'will grow well in the predicted weather conditions'},\n",
    "#     'Cotton': {'Action': 'Plant with caution', 'Considerations': 'average yield predicted however prediction model results may have low accuracy '},\n",
    "#     'Hay': {'Action': 'Do not plant', 'Considerations': 'lower than average yield in the predicted weather conditions'},\n",
    "#     'Oats': {'Action': 'Do not plant', 'Considerations': 'lower than average yield in the predicted weather conditions'},\n",
    "#     'Peanuts': {'Action': 'Plant', 'Considerations': 'will grow well in the predicted weather conditions'},\n",
    "#     'Bell Peppers': {'Action': 'Plant', 'Considerations': 'will grow well in the predicted weather conditions'},\n",
    "#     'Soybeans': {'Action': 'Plant with caution', 'Considerations': 'average yield predicted however prediction model results may have low accuracy '},\n",
    "#     'Squash': {'Action': 'Do not plant', 'Considerations': 'lower than average yield in the predicted weather conditions'},\n",
    "#     'Sweet Potatoes': {'Action': 'Do not plan', 'Considerations': 'lower than average yield in the predicted weather conditions'},\n",
    "#     'Tobacco': {'Action': 'Do not plant', 'Considerations': 'lower than average yield in the predicted weather conditions'},\n",
    "#     'Wheat': {'Action': 'Do not plant', 'Considerations': 'lower than average yield in the predicted weather conditions'}\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced98160-19e2-47f5-b169-8cabaded9fae",
   "metadata": {},
   "source": [
    "**Decision Logic Model LLM Query Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd5a0464-7c7b-4438-97a9-201ebc00d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines output output of Decisioning and Labeling function and pairs with Supplimental Information\n",
    "def generate_result(crop_yields, crop_values, confidence_levels):\n",
    "    query = \"\"\"Review the provided crop data dictionary and for each crop and respective action, create a brief narrative to describe the considerations shown. Supplement the considerations with any financial risk mitigation strategies or crop resilience advice for the respective crop.\"\"\"\n",
    "    \n",
    "    # Retrieve relevant context using the retriever\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Run the chain\n",
    "    result = llm_chain.run(context=context, query=query, crop_data=str(decisions))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ede17-c256-4f0c-ba3c-b45ec7db443a",
   "metadata": {},
   "source": [
    "**Decision Logic Model Output** _(Example)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02ac5506-342c-4b5a-b94d-9cb9166605cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mReview the provided crop data dictionary and for each crop and respective action, create a brief narrative to describe the considerations shown. Supplement the considerations with any financial risk mitigation strategies or crop resilience advice for the respective crop.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Retrieve relevant context using the retriever\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m relevant_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39mget_relevant_documents(query)\n\u001b[0;32m      5\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m relevant_docs])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Run the chain\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Review the provided crop data dictionary and for each crop and respective action, create a brief narrative to describe the considerations shown. Supplement the considerations with any financial risk mitigation strategies or crop resilience advice for the respective crop.\"\"\"\n",
    "\n",
    "# Retrieve relevant context using the retriever\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "# Run the chain\n",
    "result = results_llm_chain.run(context=context, query=query, crop_data=str(prediction_dict))\n",
    "\n",
    "# Shows results from LLM\n",
    "display (result) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee51979-ad9d-4cdb-a71a-b972d94cb7a2",
   "metadata": {},
   "source": [
    "#### 3.4 Output Parser _(for downloadable document)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "682c4ed3-ba9f-4802-bb0c-baa1fb7c46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract crop advice\n",
    "def extract_crop_advice(text, crops):\n",
    "    crops_advice = {crop: \"\" for crop in crops}\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for crop in crops:\n",
    "            if crop.lower() in sentence.lower():\n",
    "                crops_advice[crop] += sentence + \" \"\n",
    "    \n",
    "    return crops_advice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad440047-b5dc-436b-8ad3-3a3a95a73e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract crop and advice\n",
    "crops_advice = extract_crop_advice(result, crop_data.keys())\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(list(crops_advice.items()), columns=['Crop', 'Advice'])\n",
    "\n",
    "# Clean up the advice column\n",
    "df['Advice'] = df['Advice'].str.strip()\n",
    "\n",
    "# Remove rows with empty advice\n",
    "df = df[df['Advice'] != \"\"]\n",
    "\n",
    "# Sort the DataFrame by crop name\n",
    "df = df.sort_values('Crop')\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the table\n",
    "display (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d19d77b-7fdc-4896-8e8a-bda4cbb8f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save to CSV\n",
    "df.to_csv('crop_advice.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691e1b7-c9f0-4364-8162-55678d09b16c",
   "metadata": {},
   "source": [
    "## 4.0 USER INTERFACE\n",
    "**OVERVIEW**: Creates Gradio user enterface to enable user to select a count, select crops to consider and input 4-digit planting year using keyboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e87df3-9931-4893-861b-57a1390892a4",
   "metadata": {},
   "source": [
    "**IMPORTS** _(User Interface)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76262a59-d773-4b94-9665-873852be5916",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Uses Gradio to build interface\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ef3f4-cdb2-4ae1-8466-412ce7ad9852",
   "metadata": {},
   "source": [
    "### 4.1 Input Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "30cc9935-c0cd-490a-af1d-c995fff8c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the inputs for counties, crops and seasons\n",
    "counties = [\"Alamance\", \"Alexander\", \"Alleghany\", \"Anson\", \"Ashe\", \"Avery\", \"Beaufort\", \"Bertie\", \"Bladen\", \"Brunswick\",\n",
    "            \"Buncombe\", \"Burke\", \"Cabarrus\", \"Caldwell\", \"Camden\", \"Carteret\", \"Caswell\", \"Catawba\", \"Chatham\",\n",
    "            \"Cherokee\", \"Chowan\", \"Clay\", \"Cleveland\", \"Columbus\", \"Craven\", \"Cumberland\", \"Currituck\", \"Dare\",\n",
    "            \"Davidson\", \"Davie\", \"Duplin\", \"Durham\", \"Edgecombe\", \"Forsyth\", \"Franklin\", \"Gaston\", \"Gates\", \"Graham\",\n",
    "            \"Granville\", \"Greene\", \"Guilford\", \"Halifax\", \"Harnett\", \"Haywood\", \"Henderson\", \"Hertford\", \"Hoke\", \"Hyde\",\n",
    "            \"Iredell\", \"Jackson\", \"Johnston\", \"Jones\", \"Lee\", \"Lenoir\", \"Lincoln\", \"Macon\", \"Madison\", \"Martin\",\n",
    "            \"McDowell\", \"Mecklenburg\", \"Mitchell\", \"Montgomery\", \"Moore\", \"Nash\", \"New Hanover\", \"Northampton\",\n",
    "            \"Onslow\", \"Orange\", \"Pamlico\", \"Pasquotank\", \"Pender\", \"Perquimans\", \"Person\", \"Pitt\", \"Polk\", \"Randolph\",\n",
    "            \"Richmond\", \"Robeson\", \"Rockingham\", \"Rowan\", \"Rutherford\", \"Sampson\", \"Scotland\", \"Stanly\", \"Stokes\",\n",
    "            \"Surry\", \"Swain\", \"Transylvania\", \"Tyrrell\", \"Union\", \"Vance\", \"Wake\", \"Warren\", \"Washington\", \"Watauga\",\n",
    "            \"Wayne\", \"Wilkes\", \"Wilson\", \"Yadkin\", \"Yancey\"]\n",
    "\n",
    "crops = ['Barley', 'Corn', 'Hay', 'Oats', 'Peanuts', 'Bell Peppers', 'Soybeans', 'Squash',\n",
    "         'Sweet Potatoes', 'Tobacco', 'Wheat']\n",
    "\n",
    "seasons = ['Spring', 'Summer', 'Fall']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b6da1-1e1d-41a2-a0d1-1068632116c3",
   "metadata": {},
   "source": [
    "### 4.2 Input Transformation\n",
    "\n",
    "NOTE: for demonstration purposes, we simulate forecasted seasional avg temperatures (degrees F), seasional avg precipitation (inches), and weeks of D2, D3 and D4 drought conditions _(i.e., Avg Fall Temp , Avg Spring Temp, Avg Summer Temp, Avg Winter Temp,Avg Fall Precip, Avg Spring Precip, Avg Summer Precip, Avg Winter Precip, Weeks of Severe drought (D2), Weeks of Extreme Drought (D3), Weeks of Exceptional Drought)._\n",
    "\n",
    "Actual forecast can be pulled in via API from Weather forecasting service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c101a4-fd40-4c57-bf43-33ddfb3e1a56",
   "metadata": {},
   "source": [
    "**Weather Forecast Simulation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b74bea4e-5691-46c2-b193-fd1187da6c99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# function simuate weather forecast data\n",
    "def get_varied_factors():\n",
    "   \n",
    "    base_factors = [58.77, 59.8, 75.13, 42.6, 9.58, 11.03, 14.9, 8.83, 29, 15, 1]\n",
    "    \n",
    "    # Precipitation variation (first 4 values)\n",
    "    precipitation = np.array(base_factors[:4])\n",
    "    precipitation_variation = np.random.normal(0, 5, 4)  # Mean 0, std dev 5\n",
    "    varied_precipitation = np.maximum(precipitation + precipitation_variation, 0)  # Ensure non-negative\n",
    "    \n",
    "    # Temperature variation (next 4 values)\n",
    "    temperature = np.array(base_factors[4:8])\n",
    "    temperature_variation = np.random.normal(0, 2, 4)  # Mean 0, std dev 2\n",
    "    varied_temperature = temperature + temperature_variation\n",
    "    \n",
    "    # Weeks of drought variation (last 3 values)\n",
    "    drought_weeks = np.array(base_factors[8:])\n",
    "    drought_variation = np.random.randint(-2, 3, 3)  # Random integer between -2 and 2\n",
    "    varied_drought = np.maximum(drought_weeks + drought_variation, 0)  # Ensure non-negative\n",
    "    \n",
    "    # Combines all varied factors\n",
    "    varied_factors = np.concatenate([varied_precipitation, varied_temperature, varied_drought])\n",
    "\n",
    "    # returns factors array\n",
    "    return varied_factors.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412dcf1b-4bf7-4594-b192-1b503caa7753",
   "metadata": {},
   "source": [
    "**User Interface Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "76d3977f-46d1-4fcb-aeb2-1eed5183ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_interface(image, county, crop_list, selected_seasons, year):\n",
    "    # Retrieves simulated weather forecast data (in production this would be forcast data from an API call to Wx fcst svc)\n",
    "    factors = get_varied_factors()\n",
    "\n",
    "    # Converts user input into crop_prediction function input\n",
    "    crop_input = {\n",
    "        'Barley': 'BARLEY_$_ACRE',\n",
    "        'Corn': 'CORN_$_ACRE',\n",
    "        'Hay': 'HAY_$_ACRE',\n",
    "        'Oats': 'OATS_$_ACRE',\n",
    "        'Peanuts': 'PEANUTS_$_ACRE',\n",
    "        'Bell Peppers': 'PEPPERS,BELL_$_ACRE',\n",
    "        'Soybeans': 'SOYBEANS_$_ACRE',\n",
    "        'Squash': 'SQUASH_$_ACRE',\n",
    "        'Sweet Potatoes': 'SWEET_$_ACRE',\n",
    "        'Tobacco': 'TOBACCO_$_ACRE',\n",
    "        'Wheat': 'WHEAT_$_ACRE'\n",
    "    }\n",
    "   \n",
    "    # Creates dictionary to hold the prediction values for each crop\n",
    "    prediction_dict = {}\n",
    "   \n",
    "    for crop in crop_list:\n",
    "        # Function to convert crop name into CROPNAME_$_ACRE\n",
    "        model_input = crop_input[crop]\n",
    "\n",
    "        # Runs prediction model for given crop\n",
    "        cropname, prediction, avg20, conf = crop_prediction(model_input, factors)\n",
    "\n",
    "        # Appends results to prediction dictionary\n",
    "        prediction_dict[crop] = {\n",
    "            'prediction': prediction,\n",
    "            'average_20_year': avg20,\n",
    "            'confidence': conf\n",
    "        }\n",
    "    \n",
    " # Generate planting decisions based on predictions\n",
    "    decisions = process_crop_predictions(prediction_dict)\n",
    "\n",
    "    # Generate recommendations\n",
    "    recommendations = generate_recommendations(decisions)\n",
    "    \n",
    "    # Combine predictions, decisions, and recommendations\n",
    "    result = {\n",
    "        'predictions': prediction_dict,\n",
    "        'decisions': decisions,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed8a3f-722d-4cff-b750-ce332a9c7f35",
   "metadata": {},
   "source": [
    "**Recomendation Generation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9a76eb3b-d9ad-4b03-819d-6351be72ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(raw_result):\n",
    "    query = \"\"\"Review the provided crop data dictionary and for each crop and respective action, create a brief narrative to describe the considerations shown. Supplement the considerations with any financial risk mitigation strategies or crop resilience advice for the respective crop.\"\"\"\n",
    "    \n",
    "    # Retrieve relevant context using the retriever\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Run the chain\n",
    "    result = llm_chain.run(context=context, query=query, crop_data=str(raw_result))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b118f-a52e-42b4-888d-3c1fe7a349aa",
   "metadata": {},
   "source": [
    "### 4.3 Interface Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9038a76b-c126-4083-bcb9-7be326f5c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://b6c39352f06c11c8e4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b6c39352f06c11c8e4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define output to Gradio interface\n",
    "outputs = gr.JSON(label=\"Crop Predictions and Recommendations\")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "gr.Interface(\n",
    "    fn=user_interface,\n",
    "    inputs=[\n",
    "        gr.Image(value=\"Images/ui_image.png\", label=\"Farm Image\"),  \n",
    "        gr.Dropdown(choices=counties, label=\"Select County\"),\n",
    "        gr.CheckboxGroup(choices=crops, label=\"Crops to Consider\"),\n",
    "        gr.CheckboxGroup(choices=seasons, label=\"Planting Season(s)\", value=seasons),\n",
    "        gr.Number(label=\"Planting Year (YYYY)\", value=2025, minimum=2025, maximum=2035)\n",
    "    ],\n",
    "    outputs=outputs,\n",
    "    title=\"Crop Planning and Protection Plan Generator\"\n",
    ").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
