{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35b42ec-e70f-4248-b73f-4297321abcb6",
   "metadata": {},
   "source": [
    "# AG CROP PLANNING TOOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60320f7-2ca5-420c-9795-37526c39fb23",
   "metadata": {},
   "source": [
    "The Ag Decision Engine accepts inputs from a user (Crop Type, Location and Timeframe) and develops a customized crop planning and protection plan for farmland owners or operatators across North Carolina. The decision engine offers a basic interface for user input and leverages ouputs from a crop performance prediction model and a RAG-enhanced LLM for recomendation building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5bfc7-0449-444f-b4da-002a9058cf08",
   "metadata": {},
   "source": [
    "## CONTENT\n",
    "1.0 - Initial Setup\\\n",
    "2.0 - Crop Prediction Model\\\n",
    "3.0 - Decision Logic Model\\\n",
    "4.0 - Recomendation Builder\\\n",
    "5.0 - User Interface\\\n",
    "6.0 - Launch Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a292d-3e8d-4e6b-8fc5-316b8cf135e9",
   "metadata": {},
   "source": [
    "## 1.0 INITIAL SETUP\n",
    "\n",
    "**OVERVIEW:** Function to run user inputs through appropriate crop prediction models, transform results and pass data to Decision Logic Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f69903-3974-4e62-b338-b68616d03ea2",
   "metadata": {},
   "source": [
    "**IMPORTS** _(General Purpose)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c59b6760-901f-486f-bb16-49695b7be8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import path # supports file paths\n",
    "import os # supports use of environment variables\n",
    "import pandas as pd # supports use of dataframes\n",
    "import numpy as np # supports mathmatical functionality\n",
    "import json\n",
    "\n",
    "# Supports progress monitoring features\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Removes unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0d432-b6af-4b01-bfde-edc4b12b4dea",
   "metadata": {},
   "source": [
    "### 1.1 General Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b5f5bb-6f3f-4ffd-b0a3-231ef80cc775",
   "metadata": {},
   "source": [
    "**DEPENDENCIES**\n",
    "* For Natural Lanugage Processing\n",
    "    * Local LLM:  Ollama _([download]('https://ollama.com/download/windows'))_ running 'phi3:mini' model _([documentation]('https://ollama.com/library/phi3'))_\n",
    "    * Hosted LLM: OpenAI _([documentation]('https://platform.openai.com/docs/overview'))_ \n",
    "* For Document Loading, Embedding and Retrieval (RAG Functionality)\n",
    "    * LangChain _([documentation]('https://python.langchain.com/v0.2/docs/introduction/')) loads and splits documents_\n",
    "    * Unstructured _([documentation]('https://docs.unstructured.io/welcome')) pre-processes pdf documents_\n",
    "    * OpenAI _([documentation]('https://platform.openai.com/docs/guides/embeddings/')) converts documents into embeddings_\n",
    "    * ChromaDB _([documentation]('https://docs.trychroma.com/getting-started')) stores embeddings_\n",
    "\n",
    "**INSTRUCTIONS**\n",
    "1. Load or call selected LLM\n",
    "2. _(Option A, default)_ For running LLM locally:  \n",
    "    *  Download the [Ollama servce]((https://ollama.com/download)), if needed.\n",
    "    *  Start the Ollama service by running the following command:`ollama serve`\n",
    "    *  Allow Ollama service to run in the background while running code\n",
    "    *  Pull the latest update the Ollama [phi3-mini](https://ollama.com/library/phi3) model by running the following command:`ollama pull phi3:mini`\n",
    "2. _(Option B)_ For using hosted LLM (e.g., OpenAI, Claude, etc.):\n",
    "    *  Update the code in Section 1.1 below. (Code available for running OpenAI LLM; for other models, make similar code edits)\n",
    "3. Initalize LLM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cab97-6c33-49d5-bf0f-129c51094097",
   "metadata": {},
   "source": [
    "### 1.2 LLM Selection and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35fd436-073a-4b6e-b81c-41ab4d0156d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes use of local LLM (if using hosted LLM use code block below)\n",
    "import ollama\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "# For Ollama (local LLM)\n",
    "llm = Ollama(model=\"phi3:mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392d5e63-de71-41c2-bec0-d9453628af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT CODE below to use OpenAI hosted LLM (OpenAI) \n",
    "\n",
    "# import openai # for hosted LLM option\n",
    "# from langchain import OpenAI\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # reads local .env file\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cee742-b354-4aae-91a1-47dc93475e13",
   "metadata": {},
   "source": [
    "### 1.3 RAG System Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0f12e-dafd-46da-8814-fd6e5a5c0a47",
   "metadata": {},
   "source": [
    "**Helper Function for HTML Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b63293c3-e503-4e9b-b30e-7f41d4f1eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to support html files docs with different encodings\n",
    "class CustomHTMLLoader(UnstructuredFileLoader):\n",
    "    def __init__(self, file_path: str):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def _get_elements(self):\n",
    "        try:\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(self.file_path, 'r', encoding='latin-1') as f:\n",
    "                    content = f.read()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(self.file_path, 'r', encoding='cp1252') as f:\n",
    "                    content = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        text = soup.get_text(separator='\\n', strip=True)\n",
    "        return [text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36611d2a-0e58-45fe-8342-b4f83df301cd",
   "metadata": {},
   "source": [
    "**Helper Function for PDF Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276b4601-5c25-494b-bc99-275faba87034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to support loading text files with different encodings\n",
    "class CustomTextLoader(UnstructuredFileLoader):\n",
    "    def __init__(self, file_path: str):\n",
    "        super().__init__(file_path)\n",
    "\n",
    "    def _get_elements(self):\n",
    "        try:\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(self.file_path, 'r', encoding='latin-1') as f:\n",
    "                    text = f.read()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(self.file_path, 'r', encoding='cp1252') as f:\n",
    "                    text = f.read()\n",
    "        return [text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0ce2e4-2b4a-44a4-86e8-ded3730da0e3",
   "metadata": {},
   "source": [
    "**Setup RAG Document Repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683d22ae-76dc-403f-9bf4-b8723b3ae270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\Jamie\\OneDrive\\desktop\\AI_Bootcamp\\MOD_23_Project_3\\AgProject3\n"
     ]
    }
   ],
   "source": [
    "# Checks current directory path (helps user ensure correct documents_path set\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current working directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3ca2a9-7098-4c6d-a2c6-7b06e18b76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads documents from current working directory\n",
    "documents_path = './rag_content' # EDIT PATH FOR NEW DIRECTORY AS NEEDED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14021de-6975-4f38-ad54-cd07d08fbb9f",
   "metadata": {},
   "source": [
    "**Document Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1f9520f-97de-4dd1-8d62-9056260cfb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory found: ./rag_content\n",
      "Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|████████████████████████████| 6/6 [00:00<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 documents\n",
      "Encountered 0 errors\n",
      "\n",
      "Summary of loaded documents:\n",
      "pdf: 7\n",
      "html: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sets up loaders for different file types\n",
    "loaders = {\n",
    "    \"**/*.pdf\": PyPDFLoader,\n",
    "    \"**/*.html\": CustomHTMLLoader,\n",
    "    \"**/*.txt\": CustomTextLoader\n",
    "}\n",
    "# Error handling - checks if the directory exists\n",
    "if not os.path.exists(documents_path):\n",
    "    print(f\"Directory not found: {documents_path}\")\n",
    "    print(\"Contents of current directory:\")\n",
    "    print(os.listdir(os.getcwd()))\n",
    "    raise FileNotFoundError(f\"Directory {documents_path} does not exist\")\n",
    "\n",
    "print(f\"Directory found: {documents_path}\")\n",
    "\n",
    "# Selects appropriate loader\n",
    "def get_loader(file_path):\n",
    "    for glob_pattern, loader_class in loaders.items():\n",
    "        if file_path.endswith(glob_pattern.split(\"*\")[-1]):\n",
    "            return loader_class(file_path)\n",
    "    return CustomTextLoader(file_path)  # Default to CustomTextLoader\n",
    "\n",
    "# Loads documents\n",
    "print(\"Loading documents...\")\n",
    "documents = []\n",
    "errors = []\n",
    "\n",
    "for root, _, files in os.walk(documents_path):\n",
    "    for file in tqdm(files, desc=\"Processing files\"):\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            loader = get_loader(file_path)\n",
    "            docs = loader.load()\n",
    "            documents.extend(docs)\n",
    "        except Exception as e:\n",
    "            errors.append((file_path, str(e)))\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"Encountered {len(errors)} errors\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nErrors encountered:\")\n",
    "    for file_path, error in errors:\n",
    "        print(f\"{file_path}: {error}\")\n",
    "\n",
    "# Displays summary of loaded documents\n",
    "file_types = {}\n",
    "for doc in documents:\n",
    "    file_type = os.path.splitext(doc.metadata.get('source', ''))[-1].lstrip('.')\n",
    "    file_types[file_type] = file_types.get(file_type, 0) + 1\n",
    "\n",
    "print(\"\\nSummary of loaded documents:\")\n",
    "for file_type, count in file_types.items():\n",
    "    print(f\"{file_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f489d-f37a-48d9-944d-f25d01cb419c",
   "metadata": {},
   "source": [
    "**Text Spliting and Content Chunking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3995d00-dc23-4ef3-b734-3955fd3d4cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting documents: 100%|█████████████████████| 10/10 [00:00<00:00, 2250.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing document 1/10\n",
      "Document 1 size: 5276 characters\n",
      "Document 1/10 processed:\n",
      "  - Chunks created: 7\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: 3668017.22 characters/second\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 2/10\n",
      "Document 2 size: 6632 characters\n",
      "Document 2/10 processed:\n",
      "  - Chunks created: 9\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 3/10\n",
      "Document 3 size: 1079 characters\n",
      "Document 3/10 processed:\n",
      "  - Chunks created: 2\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 4/10\n",
      "Document 4 size: 18854 characters\n",
      "Document 4/10 processed:\n",
      "  - Chunks created: 24\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: 18681646.02 characters/second\n",
      "Total time elapsed: 0.00 seconds\n",
      "\n",
      "Processing document 5/10\n",
      "Document 5 size: 2475 characters\n",
      "Document 5/10 processed:\n",
      "  - Chunks created: 3\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: 2476951.18 characters/second\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Processing document 6/10\n",
      "Document 6 size: 2447 characters\n",
      "Document 6/10 processed:\n",
      "  - Chunks created: 3\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Processing document 7/10\n",
      "Document 7 size: 2671 characters\n",
      "Document 7/10 processed:\n",
      "  - Chunks created: 4\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Processing document 8/10\n",
      "Document 8 size: 2265 characters\n",
      "Document 8/10 processed:\n",
      "  - Chunks created: 3\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Processing document 9/10\n",
      "Document 9 size: 5901 characters\n",
      "Document 9/10 processed:\n",
      "  - Chunks created: 7\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Processing document 10/10\n",
      "Document 10 size: 3923 characters\n",
      "Document 10/10 processed:\n",
      "  - Chunks created: 5\n",
      "  - Time taken: 0.00 seconds\n",
      "  - Processing speed: N/A (processed too quickly to measure)\n",
      "Total time elapsed: 0.01 seconds\n",
      "\n",
      "Text splitting complete!\n",
      "Total documents processed: 10\n",
      "Total chunks created: 67\n",
      "Total characters processed: 51523\n",
      "Total time taken: 0.01 seconds\n",
      "Overall processing speed: 6464347.14 characters/second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initializes the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Initializes an empty list to store the split documents\n",
    "start_time = time.time()\n",
    "split_docs = []\n",
    "total_chunks = 0\n",
    "\n",
    "# Supports monitoring progress\n",
    "for i, doc in enumerate(tqdm(documents, desc=\"Splitting documents\")):\n",
    "    \n",
    "    # Prints count number of document being processed size of the document before processing\n",
    "    print(f\"\\nProcessing document {i+1}/{len(documents)}\")\n",
    "    print(f\"Document {i+1} size: {len(doc.page_content)} characters\")\n",
    "    \n",
    "    # Performs the text splitting\n",
    "    doc_start_time = time.time()\n",
    "    split_doc = text_splitter.split_documents([doc])\n",
    "    split_docs.extend(split_doc)\n",
    "    \n",
    "    # Calculates and prints statistics for the current document\n",
    "    doc_time = time.time() - doc_start_time\n",
    "    chunks_created = len(split_doc)\n",
    "    total_chunks += chunks_created\n",
    "    \n",
    "    print(f\"Document {i+1}/{len(documents)} processed:\")\n",
    "    print(f\"  - Chunks created: {chunks_created}\")\n",
    "    print(f\"  - Time taken: {doc_time:.2f} seconds\")\n",
    "    \n",
    "    # Error handling - avoids division by zero\n",
    "    if doc_time > 0:\n",
    "        print(f\"  - Processing speed: {len(doc.page_content) / doc_time:.2f} characters/second\")\n",
    "    else:\n",
    "        print(f\"  - Processing speed: N/A (processed too quickly to measure)\")\n",
    "    \n",
    "    print(f\"Total time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Records final statistics\n",
    "total_time = time.time() - start_time\n",
    "total_characters = sum(len(doc.page_content) for doc in documents)\n",
    "\n",
    "print(\"\\nText splitting complete!\")\n",
    "print(f\"Total documents processed: {len(documents)}\")\n",
    "print(f\"Total chunks created: {total_chunks}\")\n",
    "print(f\"Total characters processed: {total_characters}\")\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\")\n",
    "\n",
    "# Avoid division by zero in overall statistics\n",
    "if total_time > 0:\n",
    "    print(f\"Overall processing speed: {total_characters / total_time:.2f} characters/second\")\n",
    "else:\n",
    "    print(\"Overall processing speed: N/A (processed too quickly to measure)\")\n",
    "\n",
    "# Now split_docs contains all the split documents\n",
    "docs = split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139874d4-4b5f-4057-a9c2-74382a13f8e7",
   "metadata": {},
   "source": [
    "**Text Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ff1a59-216a-4faa-8b65-a90809084a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings and creating vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   0%|                               | 0/67 [02:46<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding generation and vector store creation completed.\n",
      "Total time taken: 166.53 seconds\n",
      "Average time per document: 2.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generates embeddings for the document chunks\n",
    "print(\"Generating embeddings and creating vector store...\")\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"phi3:mini\")\n",
    "\n",
    "# Creates a progress bar for tracking progress\n",
    "pbar = tqdm(total=len(docs), desc=\"Processing documents\")\n",
    "\n",
    "def embed_function(texts):\n",
    "    results = embeddings.embed_documents(texts)\n",
    "    pbar.update(len(texts))\n",
    "    return results\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nEmbedding generation and vector store creation completed.\")\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\")\n",
    "print(f\"Average time per document: {total_time/len(docs):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2411dc-9edf-4f38-b80e-93f3827cb2fc",
   "metadata": {},
   "source": [
    "**Setup Retriver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "741839c1-c30c-4617-92c5-141c342279bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a retriever using the vector store\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e934a-a487-4ba0-b614-40f9d4782a26",
   "metadata": {},
   "source": [
    "## 2.0 CROP PREDICTION MODEL\n",
    "**OVERVIEW**: Function to run user inputs through appropriate crop prediction models, transform results and pass data to Decision Logic Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f9184-de48-4298-8623-d9d616904c99",
   "metadata": {},
   "source": [
    "**DEPENDENCIES**\n",
    "* Python\n",
    "* SciKit Learn\n",
    "* Prediction models _(see [Resources](./Resources) folder)_\n",
    "\n",
    "**IMPORTS** _(Prediction Model)_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f126d60f-0f77-4973-92a1-a6ac4a36092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # For accessing modeling results\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # for transforming model inputs\n",
    "\n",
    "# ML models used for crop predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e156af-2285-4e68-a111-0cec569ab0f5",
   "metadata": {},
   "source": [
    "### 2.1 Crop Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d6444a4-71a6-42e9-9471-d2a45c4e287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets location of trained ML models\n",
    "folder = './Resources/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53dbfd8c-fca6-46e6-97c7-3ad09e10a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call appropriate prediction model and return results\n",
    "def crop_prediction(measure,factorarray):\n",
    "    \n",
    "    modelmap = {\n",
    "    'BARLEY_$_ACRE' : ['BARLEY_$_ACREgbr_model.pkl','M', 213.2],\n",
    "    'BARLEY_BU_ACRE' : ['BARLEY_BU_ACREdtr_model.pkl','M', 69.4],\n",
    "    'CORN_$_ACRE' : ['CORN_$_ACREsvr_model.pkl','L', 512.2],\n",
    "    'CORN_BU_ACRE' : ['CORN_BU_ACREgbr_model.pkl','M', 116.8],\n",
    "    'COTTON_LB_ACRE' : ['COTTON_LB_ACREsvr_model.pkl','M', 829.6],\n",
    "    'HAY_$_ACRE' : ['HAY_$_ACRErfr_model.pkl','M', 228.86],\n",
    "    'HAY_T_ACRE' : ['HAY_T_ACREsvr_model.pkl','M', 2.28],\n",
    "    'OATS_$_ACRE' : ['OATS_$_ACREsvr_model.pkl','M', 192.9],\n",
    "    'OATS_BU_ACRE' : ['OATS_BU_ACREsvr_model.pkl','M', 67.625],\n",
    "    'PEANUTS_$_ACRE' : ['PEANUTS_$_ACREsvr_model.pkl','L', 882.9],\n",
    "    'PEANUTS_LB_ACRE' : ['PEANUTS_LB_ACRErfr_model.pkl','H', 3575.4],\n",
    "    'PEPPERS, BELL_CWT_ACRE' : ['PEPPERS, BELL_CWT_ACREsvr_model.pkl','L', 209.6],\n",
    "    'PEPPERS,BELL_$_ACRE' : ['PEPPERS,BELL_$_ACREsvr_model.pkl','H', 7712.7],\n",
    "    'SOYBEANS_$_ACRE' : ['SOYBEANS_$_ACREgbr_model.pkl','M', 321.5],\n",
    "    'SOYBEANS_BU_ACRE' : ['SOYBEANS_BU_ACRElr_model.pkl','H', 33.3],\n",
    "    'SQUASH_$_ACRE' : ['SQUASH_$_ACREsvr_model.pkl','L', 3567.6],\n",
    "    'SQUASH_CWT_ACRE' : ['SQUASH_CWT_ACREdtr_model.pkl','H', 110],\n",
    "    'SWEET_$_ACRE' : ['SWEET_$_ACREsvr_model.pkl','L', 2954.9],\n",
    "    'SWEET_CWT_ACRE' : ['SWEET_CWT_ACREdtr_model.pkl','L', 117.3],\n",
    "    'TOBACCO_$_ACRE' : ['TOBACCO_$_ACREgbr_model.pkl','H', 3925.6],\n",
    "    'TOBACCO_LB_ACRE' : ['TOBACCO_LB_ACREsvr_model.pkl','M', 2119.2],\n",
    "    'WHEAT_$_ACRE' : ['WHEAT_$_ACREsvr_model.pkl','M', 267.3],\n",
    "    'WHEAT_BU_ACRE' : ['WHEAT_BU_ACREgbr_model.pkl','H', 53]\n",
    "    }\n",
    "\n",
    "\n",
    "   #print('entering crop_prediction with',measure,'and',factorarray)\n",
    "\n",
    "    if measure not in modelmap.keys():\n",
    "        print('invalid measure',measure,'. Valid measures are\\n',modelmap.keys())\n",
    "        return None\n",
    "    \n",
    "    modelfile = folder + modelmap[measure][0]\n",
    "    #print(modelfile)\n",
    "    scalar_X_file = modelfile.replace(\"model\",\"X\")\n",
    "    scalar_y_file = modelfile.replace(\"model\",\"y\")\n",
    "    #print('about to open files',modelfile,scalar_X_file,scalar_y_file)\n",
    "\n",
    "    with open(modelfile, 'rb') as file:\n",
    "        #print('opened',modelfile)\n",
    "        loaded_model = pickle.load(file)\n",
    "\n",
    "    with open(scalar_X_file, 'rb') as file:\n",
    "        #print('opened',scalar_X_file)\n",
    "        loaded_X_scaler = pickle.load(file)\n",
    "\n",
    "    with open(scalar_y_file, 'rb') as file:\n",
    "        #print('opened',scalar_y_file)\n",
    "        loaded_y_scaler = pickle.load(file)\n",
    "\n",
    "    #print('loaded',modelfile,scalar_X_file,scalar_y_file)\n",
    "    \n",
    "    factorarray = np.array(factorarray).reshape(1, -1)\n",
    "    #display(factorarray.shape)\n",
    "\n",
    "    # When making predictions:\n",
    "    X_scaled = loaded_X_scaler.transform(factorarray)  # Scale new input data\n",
    "    y_pred_scaled = loaded_model.predict(X_scaled)\n",
    "    y_pred = loaded_y_scaler.inverse_transform(y_pred_scaled.reshape(-1,1))  # Inverse transform predictions\n",
    "    \n",
    "    conf = modelmap[measure][1]\n",
    "    avg20 = modelmap[measure][2]\n",
    "\n",
    "    #Returns crop name, predicted $/acre value, 20-average $/acre value and L/M/H modeling confidence \n",
    "    return measure.split('_')[0], y_pred[0][0], avg20, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0655cc9-98a4-4c6a-9301-3a65a8429e87",
   "metadata": {},
   "source": [
    "## 3.0 DECISION LOGIC MODEL\n",
    "\n",
    "**OVERVIEW**: Function to take predicted $/acre peformance of selected crop(s) with respective 20-year average performance and determine if a crop should be planted, planted with caution or not planted. Includes LLM call to generate decision justification narrative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf662e-2094-49b3-8b69-6e278538f3ef",
   "metadata": {},
   "source": [
    "**IMPORTS** _(Decision Logic)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe08ac18-e8f7-4c58-bd1f-e698e21112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6a46c-af4a-4404-aa84-56dc1c7e5822",
   "metadata": {},
   "source": [
    "### 3.1 Decisioning and Labeling Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ebe41e6-7b1b-4463-bb0a-8c9ae35ae772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in dictionary of crops' predicted $/acre, 20-year average $/acre and H/M/L modeling confidence\n",
    "# Returns dictionary with justification narrative added \n",
    "\n",
    "def make_crop_decision(prediction_dict):\n",
    "    # Initialize the Ollama model\n",
    "    llm = Ollama(model=\"phi3:mini\")\n",
    "\n",
    "    # Creates a prompt template to generate supporting narrative for decision and label\n",
    "    decision_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"crop\", \"action\", \"prediction_percentage\", \"confidence\"],\n",
    "        template=\"Generate a brief narrative explaining why the crop {crop} is labeled as '{action}'. \"\n",
    "                 \"The prediction is {prediction_percentage}% of the 20-year average, \"\n",
    "                 \"and the confidence level is {confidence}. \"\n",
    "                 \"Provide considerations for planting based on these factors.\"\n",
    "    )\n",
    "\n",
    "    # Create the RunnableSequence\n",
    "    decision_chain = decision_prompt_template | llm\n",
    "\n",
    "    crop_decisions = {}\n",
    "\n",
    "    for crop, data in prediction_dict.items():\n",
    "        prediction = data['prediction']\n",
    "        avg20 = data['average_20_year']\n",
    "        confidence = data['confidence']\n",
    "\n",
    "        # Calculate the prediction as a percentage of the 20-year average\n",
    "        prediction_percentage = (prediction / avg20) * 100\n",
    "\n",
    "        # Assign initial label based on prediction percentage\n",
    "        if prediction_percentage > 85:\n",
    "            action = 'Plant'\n",
    "        elif 60 <= prediction_percentage <= 80:\n",
    "            action = 'Plant with caution'\n",
    "            if confidence == 'L':\n",
    "                action += ' (low confidence)'\n",
    "        else:\n",
    "            action = 'Do not plant. Consider alternatives'\n",
    "\n",
    "        # Generate narrative using the LLM\n",
    "        decision_narrative = decision_chain.invoke({\n",
    "            \"crop\": crop,\n",
    "            \"action\": action,\n",
    "            \"prediction_percentage\": prediction_percentage,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "        crop_decisions[crop] = {\n",
    "            'Action': action,\n",
    "            'Considerations': decision_narrative.strip()\n",
    "        }\n",
    "\n",
    "    return crop_decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae235c4-44d0-4ae6-b84a-8490f6a12c98",
   "metadata": {},
   "source": [
    "## 4.0 RECOMENDATION BUILDER\n",
    "**OVERVIEW**: Accepts dataframe variable containing crop performance and associated justifications. Generates recommendation narrative for each crop using LLM. Supplements recommendation with additional considerations and mitagation information retrieve from RAG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b4c30-23b6-4d44-be59-8531b28ce5b8",
   "metadata": {},
   "source": [
    "**IMPORTS** _(Recommendation Builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ed8ffea-11f5-4f37-842f-a9931205e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading various document types\n",
    "from langchain_community.document_loaders import PyPDFLoader, BSHTMLLoader, UnstructuredFileLoader, DirectoryLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# Libraries for prompting and parsing\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Libraries for Output Parser\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "#nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e691db-c9e6-4497-b7ff-073cba2b4861",
   "metadata": {},
   "source": [
    "#### 4.1 Recommendation Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "00f1711c-24db-428c-9889-b67e1c2d9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "results_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\", \"crop_data\"],\n",
    "    template=\"\"\"You are an agricultural specialist who advises farmers on how to optimize farm operations and mitigate against weather and climate disasters. \n",
    "\n",
    "Use the following context to inform your answer:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Crop Data: {crop_data}\n",
    "\n",
    "Please provide a detailed response, creating a brief narrative for each crop and its respective action. Include considerations shown and supplement with financial risk mitigation strategies or crop resilience advice for each crop.\n",
    "\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "# Create an LLMChain\n",
    "results_llm_chain = results_prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d208c3-6d5e-4976-8b1d-eb68e712b77b",
   "metadata": {},
   "source": [
    "### 4.2 Recommendation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9a76eb3b-d9ad-4b03-819d-6351be72ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create risk mitagation strategies narrative to accompany decision and justification narrative (raw_results)\n",
    "def generate_recommendations(crop_decisions):\n",
    "\n",
    "    query = \"\"\"Review the provided crop decisions dictionary and for each crop and respective action, create a brief narrative to describe the considerations shown. Supplement the considerations with any financial risk mitigation strategies or crop resilience advice for the respective crop.\"\"\"\n",
    "    \n",
    "    # Retrieves relevant guidence and risk management strategies using the RAG retriever\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Run the chain\n",
    "    result = results_llm_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"query\": query,\n",
    "        \"crop_data\": str(crop_decisions)\n",
    "    })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd5a0464-7c7b-4438-97a9-201ebc00d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines output output of Decisioning and Labeling function and pairs with Supplimental Information\n",
    "def generate_final_recommendation(results_dict):\n",
    "    query = \"\"\"Review the provided crop data dictionary and for each crop and respective action, create a brief narrative to describe the considerations shown. Supplement the considerations with any financial risk mitigation strategies or crop resilience advice for the respective crop.\"\"\"\n",
    "    \n",
    "    # Retrieve relevant context using the retriever\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Run the chain\n",
    "    recommendation_narrative = results_llm_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"query\": query,\n",
    "        \"crop_data\": str(results_dict)\n",
    "    })\n",
    "    \n",
    "    return recommendation_narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691e1b7-c9f0-4364-8162-55678d09b16c",
   "metadata": {},
   "source": [
    "## 5.0 USER INTERFACE\n",
    "**OVERVIEW**: Creates Gradio user enterface to enable user to select a count, select crops to consider and input 4-digit planting year using keyboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643e854-d065-49bc-97ea-8fb34b73755a",
   "metadata": {},
   "source": [
    "**IMPORTS** _(User Interface)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76262a59-d773-4b94-9665-873852be5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Gradio to build interface\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ef3f4-cdb2-4ae1-8466-412ce7ad9852",
   "metadata": {},
   "source": [
    "### 5.1 Input Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30cc9935-c0cd-490a-af1d-c995fff8c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the inputs for counties, crops and seasons\n",
    "counties = [\"Alamance\", \"Alexander\", \"Alleghany\", \"Anson\", \"Ashe\", \"Avery\", \"Beaufort\", \"Bertie\", \"Bladen\", \"Brunswick\",\n",
    "            \"Buncombe\", \"Burke\", \"Cabarrus\", \"Caldwell\", \"Camden\", \"Carteret\", \"Caswell\", \"Catawba\", \"Chatham\",\n",
    "            \"Cherokee\", \"Chowan\", \"Clay\", \"Cleveland\", \"Columbus\", \"Craven\", \"Cumberland\", \"Currituck\", \"Dare\",\n",
    "            \"Davidson\", \"Davie\", \"Duplin\", \"Durham\", \"Edgecombe\", \"Forsyth\", \"Franklin\", \"Gaston\", \"Gates\", \"Graham\",\n",
    "            \"Granville\", \"Greene\", \"Guilford\", \"Halifax\", \"Harnett\", \"Haywood\", \"Henderson\", \"Hertford\", \"Hoke\", \"Hyde\",\n",
    "            \"Iredell\", \"Jackson\", \"Johnston\", \"Jones\", \"Lee\", \"Lenoir\", \"Lincoln\", \"Macon\", \"Madison\", \"Martin\",\n",
    "            \"McDowell\", \"Mecklenburg\", \"Mitchell\", \"Montgomery\", \"Moore\", \"Nash\", \"New Hanover\", \"Northampton\",\n",
    "            \"Onslow\", \"Orange\", \"Pamlico\", \"Pasquotank\", \"Pender\", \"Perquimans\", \"Person\", \"Pitt\", \"Polk\", \"Randolph\",\n",
    "            \"Richmond\", \"Robeson\", \"Rockingham\", \"Rowan\", \"Rutherford\", \"Sampson\", \"Scotland\", \"Stanly\", \"Stokes\",\n",
    "            \"Surry\", \"Swain\", \"Transylvania\", \"Tyrrell\", \"Union\", \"Vance\", \"Wake\", \"Warren\", \"Washington\", \"Watauga\",\n",
    "            \"Wayne\", \"Wilkes\", \"Wilson\", \"Yadkin\", \"Yancey\"]\n",
    "\n",
    "crops = ['Barley', 'Corn', 'Hay', 'Oats', 'Peanuts', 'Bell Peppers', 'Soybeans', 'Squash',\n",
    "         'Sweet Potatoes', 'Tobacco', 'Wheat']\n",
    "\n",
    "seasons = ['Spring', 'Summer', 'Fall']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b6da1-1e1d-41a2-a0d1-1068632116c3",
   "metadata": {},
   "source": [
    "### 5.2 Input Transformation\n",
    "\n",
    "NOTE: for demonstration purposes, we simulate forecasted seasional avg temperatures (degrees F), seasional avg precipitation (inches), and weeks of D2, D3 and D4 drought conditions _(i.e., Avg Fall Temp , Avg Spring Temp, Avg Summer Temp, Avg Winter Temp,Avg Fall Precip, Avg Spring Precip, Avg Summer Precip, Avg Winter Precip, Weeks of Severe drought (D2), Weeks of Extreme Drought (D3), Weeks of Exceptional Drought)._\n",
    "\n",
    "Actual forecast can be pulled in via API from Weather forecasting service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c101a4-fd40-4c57-bf43-33ddfb3e1a56",
   "metadata": {},
   "source": [
    "**Weather Forecast Simulation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b74bea4e-5691-46c2-b193-fd1187da6c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function simuate weather forecast data\n",
    "def get_varied_factors():\n",
    "   \n",
    "    base_factors = [58.77, 59.8, 75.13, 42.6, 9.58, 11.03, 14.9, 8.83, 29, 15, 1]\n",
    "    \n",
    "    # Precipitation variation (first 4 values)\n",
    "    precipitation = np.array(base_factors[:4])\n",
    "    precipitation_variation = np.random.normal(0, 5, 4)  # Mean 0, std dev 5\n",
    "    varied_precipitation = np.maximum(precipitation + precipitation_variation, 0)  # Ensure non-negative\n",
    "    \n",
    "    # Temperature variation (next 4 values)\n",
    "    temperature = np.array(base_factors[4:8])\n",
    "    temperature_variation = np.random.normal(0, 2, 4)  # Mean 0, std dev 2\n",
    "    varied_temperature = temperature + temperature_variation\n",
    "    \n",
    "    # Weeks of drought variation (last 3 values)\n",
    "    drought_weeks = np.array(base_factors[8:])\n",
    "    drought_variation = np.random.randint(-2, 3, 3)  # Random integer between -2 and 2\n",
    "    varied_drought = np.maximum(drought_weeks + drought_variation, 0)  # Ensure non-negative\n",
    "    \n",
    "    # Combines all varied factors\n",
    "    varied_factors = np.concatenate([varied_precipitation, varied_temperature, varied_drought])\n",
    "\n",
    "    # returns factors array\n",
    "    return varied_factors.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412dcf1b-4bf7-4594-b192-1b503caa7753",
   "metadata": {},
   "source": [
    "**User Interface Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "76d3977f-46d1-4fcb-aeb2-1eed5183ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to run the entire process (input ->prediction -> decision - > strategies -> recommendation narrative)\n",
    "def user_interface(image, county, crop_list, selected_seasons, year):\n",
    "    # Retrieves simulated weather forecast data\n",
    "    factors = get_varied_factors()\n",
    "\n",
    "    # Converts user input into crop_prediction function input\n",
    "    crop_input = {\n",
    "        'Barley': 'BARLEY_$_ACRE',\n",
    "        'Corn': 'CORN_$_ACRE',\n",
    "        'Hay': 'HAY_$_ACRE',\n",
    "        'Oats': 'OATS_$_ACRE',\n",
    "        'Peanuts': 'PEANUTS_$_ACRE',\n",
    "        'Bell Peppers': 'PEPPERS,BELL_$_ACRE',\n",
    "        'Soybeans': 'SOYBEANS_$_ACRE',\n",
    "        'Squash': 'SQUASH_$_ACRE',\n",
    "        'Sweet Potatoes': 'SWEET_$_ACRE',\n",
    "        'Tobacco': 'TOBACCO_$_ACRE',\n",
    "        'Wheat': 'WHEAT_$_ACRE'\n",
    "    }\n",
    "   \n",
    "    # Creates dictionary to hold the prediction values for each crop\n",
    "    prediction_dict = {}\n",
    "   \n",
    "    for crop in crop_list:\n",
    "        # Function to convert crop name into CROPNAME_$_ACRE\n",
    "        model_input = crop_input[crop]\n",
    "\n",
    "        # Runs prediction model for given crop\n",
    "        cropname, prediction, avg20, conf = crop_prediction(model_input, factors)\n",
    "\n",
    "        # Appends results to prediction dictionary\n",
    "        prediction_dict[crop] = {\n",
    "            'prediction': float(prediction),  # Ensure this is a float\n",
    "            'average_20_year': float(avg20),  # Ensure this is a float\n",
    "            'confidence': conf\n",
    "        }\n",
    "    \n",
    "    # Generates planting decisions with justification based on crop predictions\n",
    "    crop_decisions = make_crop_decision(prediction_dict)\n",
    "\n",
    "    # Expands decisions into full recommendations with risk mitigation strategies\n",
    "    recommendations = generate_recommendations(crop_decisions)\n",
    "    \n",
    "    # Combine predicted $/acre, decisions, and recommendations\n",
    "    results_dict = {\n",
    "        'predictions': prediction_dict,\n",
    "        'decisions': crop_decisions,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "    final_recommendation = generate_final_recommendation(results_dict)\n",
    "      \n",
    "    # Convert the final recommendation to a JSON-serializable format\n",
    "    json_output = json.dumps({\n",
    "        'county': county,\n",
    "        'selected_seasons': selected_seasons,\n",
    "        'year': year,\n",
    "        'final_recommendation': final_recommendation\n",
    "    }, default=str)\n",
    "    \n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed8a3f-722d-4cff-b750-ce332a9c7f35",
   "metadata": {},
   "source": [
    "**Recomendation Generation Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b118f-a52e-42b4-888d-3c1fe7a349aa",
   "metadata": {},
   "source": [
    "# 6.0 Launch Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee51979-ad9d-4cdb-a71a-b972d94cb7a2",
   "metadata": {},
   "source": [
    "**Launches Gradio U/I**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9038a76b-c126-4083-bcb9-7be326f5c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://4b126e80b918f25189.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4b126e80b918f25189.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define output to Gradio interface\n",
    "outputs = gr.JSON(label=\"Crop Predictions and Recommendations\")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "gr.Interface(\n",
    "    fn=user_interface,\n",
    "    inputs=[\n",
    "        gr.Image(value=\"Images/ui_image.png\", label=\"Farm Image\"),  \n",
    "        gr.Dropdown(choices=counties, label=\"Select County\"),\n",
    "        gr.CheckboxGroup(choices=crops, label=\"Crops to Consider\"),\n",
    "        gr.CheckboxGroup(choices=seasons, label=\"Planting Season(s)\", value=seasons),\n",
    "        gr.Number(label=\"Planting Year (YYYY)\", value=2025, minimum=2025, maximum=2035)\n",
    "    ],\n",
    "    outputs=outputs,\n",
    "    title=\"Crop Planning and Protection Plan Generator\"\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac2696-ec8e-4da8-9661-2804c92c90bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
